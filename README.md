# RecipeMe Scraper API

API intelligente de scraping et d'extraction de recettes depuis les r√©seaux sociaux (Instagram, TikTok) utilisant l'IA multimodale Google Gemini 1.5 Flash.

## üéØ Fonctionnalit√©s

### Scraping Hybride Intelligent

* **Scraping Web** : Extraction automatique depuis le DOM, meta tags et screenshots.
* **Analyse Vid√©o IA** : Fallback automatique vers l'analyse vid√©o/audio si les donn√©es web sont incompl√®tes.
* **D√©tection d'incompl√©tude** : Gemini d√©tecte automatiquement si les informations extraites sont insuffisantes et bascule sur l'analyse vid√©o.

### Analyse Multimodale

* **Vision** : Analyse des screenshots et images.
* **Audio + Vid√©o** : Analyse compl√®te des vid√©os (visuel + audio) pour extraire les recettes.
* **Optimisation RAM** : Limitation √† 720p pour √©conomiser la m√©moire.

### M√©triques et Monitoring

* **Tokens Gemini** : Suivi des tokens d'entr√©e, de sortie et totaux.
* **Co√ªts estim√©s** : Calcul automatique des co√ªts en EUR par requ√™te.
* **Ressources syst√®me** : Monitoring CPU, RAM, r√©seau et disque.

## üõ°Ô∏è Challenges Techniques & Solutions

Le d√©ploiement de ce scraper sur une infrastructure Cloud (type Hetzner/AWS) a n√©cessit√© de surmonter plusieurs d√©fis techniques li√©s aux protections anti-bot et √† l'architecture Docker.

### 1. Blocage des IPs Datacenter (Instagram)

Les r√©seaux sociaux bloquent agressivement les requ√™tes provenant d'adresses IP de centres de donn√©es (Hetzner, AWS) lorsqu'elles sont anonymes, renvoyant des erreurs 429 ou des redirections de login.

* **Solution** : Impl√©mentation d'un syst√®me d'authentification par cookies (`cookies.txt` au format Netscape). Cela permet d'authentifier la requ√™te comme venant d'un utilisateur l√©gitime, contournant le blocage g√©ographique/IP.

### 2. Gestion des Permissions Docker (Read-Only)

La librairie `yt-dlp` tente par d√©faut de r√©√©crire le fichier de cookies pour maintenir la session, ce qui √©choue dans un conteneur Docker o√π les montages sont souvent en lecture seule ou d√©tenus par root (`OSError: Read-only file system`).

* **Solution** : Le service effectue une copie √† la vol√©e du fichier `cookies.txt` vers le r√©pertoire temporaire du conteneur (`/tmp`) avant chaque ex√©cution. Cela garantit l'acc√®s en √©criture n√©cessaire sans corrompre le fichier source.

### 3. Fragmentation des Formats Vid√©o

Les formats de diffusion (Reels) changent fr√©quemment (audio s√©par√©, conteneurs mp4/webm), faisant √©chouer les strat√©gies de t√©l√©chargement strictes.

* **Solution** : Mise en place d'un algorithme de **Fallback en cascade**. L'API tente plusieurs strat√©gies de la plus pr√©cise √† la plus g√©n√©rique (ex: "720p Optimized" ‚Üí "MP4 Fallback" ‚Üí "Best Available"), assurant un taux de succ√®s maximal.

> **‚öñÔ∏è Note √âthique & L√©gale** : L'utilisation de cookies permet l'interop√©rabilit√© technique n√©cessaire au fonctionnement sur serveur. Cependant, ce projet est con√ßu pour un usage personnel, √©ducatif ou de d√©monstration. Le scraping massif de donn√©es peut violer les Conditions d'Utilisation (ToS) des plateformes. Il est recommand√© d'utiliser un compte d√©di√© secondaire et de respecter des d√©lais raisonnables entre les requ√™tes.

## üèóÔ∏è Architecture

```mermaid
graph TD
    Client[Client API] --> Express[Express API]
    Express --> Queue[P-Queue (Concurrency: 1)]
    Queue --> Scraper[Scraper Service]
    Scraper -->|Playwright| Web[Web Analysis]
    Web --> Check{Data Complete?}
    Check -->|Yes| Return[Return JSON]
    Check -->|No| VideoAgent[Video Agent]
    VideoAgent -->|Cookies Auth| YTDLP[yt-dlp]
    YTDLP -->|Video File| Gemini[Gemini 1.5 Flash]
    Gemini --> Return

```

## üìã Pr√©requis

* **Node.js** 20+ (ou Docker)
* **Docker** et **Docker Compose**
* **Cl√© API Google Gemini** (`GEMINI_API_KEY`)
* **Fichier(s) Cookies** : Format Netscape (ex. extension "Get cookies.txt LOCALLY"). **Instagram** : `cookies.txt` depuis instagram.com. **TikTok** : les cookies sont **par domaine** ‚Äî un fichier export√© depuis Instagram ne suffit pas pour TikTok ; il faut exporter depuis tiktok.com dans `cookies-tiktok.txt` (ou `COOKIES_TIKTOK_PATH`).

## üöÄ Installation

### Option 1 : Docker (Recommand√©)

1. **Cloner le repository**

```bash
git clone <repository-url>
cd scraper-api

```

2. **Configuration**

```bash
cp .env.example .env
# Ajouter votre GEMINI_API_KEY dans le fichier .env

```

3. **Pr√©paration des Cookies**
* Installez l'extension "Get cookies.txt LOCALLY" (Chrome/Firefox).
* **Instagram** : connectez-vous √† Instagram, exportez les cookies dans `cookies.txt`, placez-le √† la racine.
* **TikTok** : connectez-vous √† tiktok.com, exportez les cookies dans `cookies-tiktok.txt` √† la racine (ou d√©finissez `COOKIES_TIKTOK_PATH`). Sans cela, les liens TikTok peuvent √©chouer (blocage / login requis depuis un datacenter).

4. **D√©marrage**

```bash
docker compose up --build -d

```

### Option 2 : Installation Locale

```bash
npm install
npm run build
npm start

```

## üîß Configuration

### Variables d'environnement (.env)

```env
PORT=5000
GEMINI_API_KEY=votre_cle_api_ici
NODE_ENV=production
# Base de donn√©es (SQLite par d√©faut)
DATABASE_URL="file:./prisma/dev.db"
# Cookies (format Netscape). Instagram par d√©faut.
COOKIES_PATH=/app/cookies.txt
# Optionnel : cookies TikTok (obligatoire si vous scrapez des liens TikTok depuis un datacenter)
COOKIES_TIKTOK_PATH=/app/cookies-tiktok.txt

```

### Volume Docker

Le fichier `docker-compose.yml` doit monter le fichier de cookies :

```yaml
services:
  scraper-api:
    volumes:
      - ./cookies.txt:/app/cookies.txt:ro  # Montage en lecture seule (copi√© dans /tmp par l'app)

```

## üì° Utilisation de l'API

### Endpoint : `/process`

**Requ√™te :**

```bash
POST http://localhost:5000/process
Content-Type: application/json

{
  "url": "https://www.instagram.com/reel/DRNDWfBiFpn/",
  "forceVideo": false,
  "save": true,
  "tagIds": ["id_tag1"],
  "folderId": "id_dossier_ou_null"
}

```

**R√©ponse (Exemple Succ√®s) :**

```json
{
  "success": true,
  "method": "video_ai",
  "data": {
    "id": "clx...",
    "title": "Filet de poisson blanc sauce cr√©meuse",
    "ingredients": ["Cabillaud", "Moutarde", "Cr√®me", "Haricots verts"],
    "steps": ["Saisir le poisson", "Pr√©parer la sauce", "Servir chaud"],
    "source_url": "https://..."
  },
  "saved": true,
  "usage": {
    "totalTokens": 18288,
    "costEUR": 0.0013
  }
}

```

### Recettes, tags et dossiers

- **GET /recipes?q=...&tagIds=id1,id2&folderId=...** ‚Äî Liste avec recherche (titre, ingr√©dients, √©tapes) et filtres par tags (tous requis) et dossier.
- **GET /recipes/:id** ‚Äî D√©tail. **POST /recipes** ‚Äî Cr√©er (body : title, ingredients, steps, source_url, tagIds, folderId). **PATCH /recipes/:id** ‚Äî Modifier. **DELETE /recipes/:id** ‚Äî Supprimer.
- **GET /tags** ‚Äî Liste des tags. **POST /tags** ‚Äî Cr√©er (body : `{ "name": "sucr√©" }`).
- **GET /folders** ‚Äî Liste des dossiers. **GET /folders/:id** ‚Äî D√©tail + recettes. **POST /folders** ‚Äî Cr√©er. **PATCH /folders/:id** ‚Äî Renommer. **DELETE /folders/:id** ‚Äî Supprimer (recettes conserv√©es).

## üí∞ Co√ªts et Performance

L'API utilise **Gemini 1.5 Flash**, choisi pour son excellent rapport performance/co√ªt sur l'analyse multimodale.

| M√©thode | Co√ªt Moyen (EUR) | Tokens Moyens |
| --- | --- | --- |
| **Web Scraping** (Texte seul) | ~0.0002 ‚Ç¨ | 1k - 3k |
| **Analyse Vid√©o** (Vision + Audio) | ~0.0015 ‚Ç¨ | 15k - 25k |

*Note : L'analyse vid√©o consomme plus de tokens car Gemini analyse le flux visuel image par image, mais reste tr√®s √©conomique (~1.50‚Ç¨ pour 1000 vid√©os).*

## üîí S√©curit√©

* **Isolation** : Ex√©cution dans un conteneur Docker s√©curis√©.
* **Nettoyage** : Suppression automatique des vid√©os t√©l√©charg√©es et cookies temporaires apr√®s analyse.
* **Rate Limiting** : Protection contre les abus d'API.
* **Confidentialit√©** : Les cookies ne sont jamais expos√©s dans les logs ou les r√©ponses API.

## ü§ù Contribution

Les contributions sont bienvenues !

1. Fork le projet
2. Cr√©er une branche (`git checkout -b feature/amazing-feature`)
3. Commit les changements (`git commit -m 'Add amazing feature'`)
4. Push vers la branche (`git push origin feature/amazing-feature`)
5. Ouvrir une Pull Request

## üìÑ Licence

ISC

---

**Version** : 1.1.0

**Auteur** : Chhaju CHAKMA
